{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import *\n\n# Read multiline json file 1\ndata_df = spark.read.option(\"multiline\",\"false\") \\\n      .json(\"/FileStore/tables/JSON/examples.json\")\ndisplay(data_df) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a7ff580-45a3-413e-933f-eb3ef85b8081"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[["5ee69d943260aab97ea0d58d"],null,null,null,null,null,null,null,null,null,null,null,null,"Pizza",null],[["5ee69e393260aab97ea0d58e"],null,null,null,null,null,null,null,null,null,null,null,null,"Delete me",null],[["5e5e9c470d33e9e8e3891b35"],210,20,"Classic Mexican tacos",["Brown beef","Add taco seasoning and water, mix","Bring to boil","Lower heat to simmer 5-10 minutes until desired consistency","Put meat in tacos"],[["ground beef (lean)",[1,"lbs"]],["taco seasoning",[2,"oz"]],["corn hard tacos",[12,"oz"]]],[1,415],2,10,[4,4,3,4,2,5,2,2,4,5],3.5,4,["mexican","quick","easy","ground beef"],"Tacos","Dinner"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"_id","type":"{\"type\":\"struct\",\"fields\":[{\"name\":\"$oid\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}","metadata":"{}"},{"name":"calories_per_serving","type":"\"long\"","metadata":"{}"},{"name":"cook_time","type":"\"long\"","metadata":"{}"},{"name":"desc","type":"\"string\"","metadata":"{}"},{"name":"directions","type":"{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}","metadata":"{}"},{"name":"ingredients","type":"{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"name\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"quantity\",\"type\":{\"type\":\"struct\",\"fields\":[{\"name\":\"amount\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"unit\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true}","metadata":"{}"},{"name":"likes","type":"{\"type\":\"array\",\"elementType\":\"long\",\"containsNull\":true}","metadata":"{}"},{"name":"likes_count","type":"\"long\"","metadata":"{}"},{"name":"prep_time","type":"\"long\"","metadata":"{}"},{"name":"rating","type":"{\"type\":\"array\",\"elementType\":\"long\",\"containsNull\":true}","metadata":"{}"},{"name":"rating_avg","type":"\"double\"","metadata":"{}"},{"name":"servings","type":"\"long\"","metadata":"{}"},{"name":"tags","type":"{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}","metadata":"{}"},{"name":"title","type":"\"string\"","metadata":"{}"},{"name":"type","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>_id</th><th>calories_per_serving</th><th>cook_time</th><th>desc</th><th>directions</th><th>ingredients</th><th>likes</th><th>likes_count</th><th>prep_time</th><th>rating</th><th>rating_avg</th><th>servings</th><th>tags</th><th>title</th><th>type</th></tr></thead><tbody><tr><td>List(5ee69d943260aab97ea0d58d)</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>Pizza</td><td>null</td></tr><tr><td>List(5ee69e393260aab97ea0d58e)</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>Delete me</td><td>null</td></tr><tr><td>List(5e5e9c470d33e9e8e3891b35)</td><td>210</td><td>20</td><td>Classic Mexican tacos</td><td>List(Brown beef, Add taco seasoning and water, mix, Bring to boil, Lower heat to simmer 5-10 minutes until desired consistency, Put meat in tacos)</td><td>List(List(ground beef (lean), List(1, lbs)), List(taco seasoning, List(2, oz)), List(corn hard tacos, List(12, oz)))</td><td>List(1, 415)</td><td>2</td><td>10</td><td>List(4, 4, 3, 4, 2, 5, 2, 2, 4, 5)</td><td>3.5</td><td>4</td><td>List(mexican, quick, easy, ground beef)</td><td>Tacos</td><td>Dinner</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# directions columns contains Array lets try to flat it out...\n\n#Using SQL col() function\nfrom pyspark.sql.functions import col\ndata_df2= data_df[\"title\",\"directions\"].filter(col(\"title\")==\"Tacos\")\n\ndisplay(data_df2)\n\nfrom pyspark.sql.functions import explode\ndisplay(  data_df2.select(data_df2.title,explode(data_df2.directions))  ) # explode function used for flat it out...\n\ndata_df3=data_df2.select(data_df2.title,explode(data_df2.directions))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68b5f941-5d13-4adf-a466-4b279ff20014"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Tacos",["Brown beef","Add taco seasoning and water, mix","Bring to boil","Lower heat to simmer 5-10 minutes until desired consistency","Put meat in tacos"]]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"title","type":"\"string\"","metadata":"{}"},{"name":"directions","type":"{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>title</th><th>directions</th></tr></thead><tbody><tr><td>Tacos</td><td>List(Brown beef, Add taco seasoning and water, mix, Bring to boil, Lower heat to simmer 5-10 minutes until desired consistency, Put meat in tacos)</td></tr></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Tacos","Brown beef"],["Tacos","Add taco seasoning and water, mix"],["Tacos","Bring to boil"],["Tacos","Lower heat to simmer 5-10 minutes until desired consistency"],["Tacos","Put meat in tacos"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"title","type":"\"string\"","metadata":"{}"},{"name":"col","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>title</th><th>col</th></tr></thead><tbody><tr><td>Tacos</td><td>Brown beef</td></tr><tr><td>Tacos</td><td>Add taco seasoning and water, mix</td></tr><tr><td>Tacos</td><td>Bring to boil</td></tr><tr><td>Tacos</td><td>Lower heat to simmer 5-10 minutes until desired consistency</td></tr><tr><td>Tacos</td><td>Put meat in tacos</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Use array() function to create a new array column by merging the data from multiple columns.\n\nfrom pyspark.sql.functions import array\n\ndisplay( data_df3.select(data_df3.title,array(data_df3.title,data_df3.col).alias(\"Dummy_array\")) )\n\n#display( data_df3.select(data_df3.title,array(data_df3.title,data_df3.col)[1].alias(\"Dummy_array\")) )\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4cb552d4-2b10-40da-8ba3-627c81c54499"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Tacos",["Tacos","Brown beef"]],["Tacos",["Tacos","Add taco seasoning and water, mix"]],["Tacos",["Tacos","Bring to boil"]],["Tacos",["Tacos","Lower heat to simmer 5-10 minutes until desired consistency"]],["Tacos",["Tacos","Put meat in tacos"]]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"title","type":"\"string\"","metadata":"{}"},{"name":"Dummy_array","type":"{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>title</th><th>Dummy_array</th></tr></thead><tbody><tr><td>Tacos</td><td>List(Tacos, Brown beef)</td></tr><tr><td>Tacos</td><td>List(Tacos, Add taco seasoning and water, mix)</td></tr><tr><td>Tacos</td><td>List(Tacos, Bring to boil)</td></tr><tr><td>Tacos</td><td>List(Tacos, Lower heat to simmer 5-10 minutes until desired consistency)</td></tr><tr><td>Tacos</td><td>List(Tacos, Put meat in tacos)</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, ArrayType\n\ndata_schema = StructType(\n  [\n    StructField(\"Title\",StringType(),True),\n    StructField(\"Desc\",ArrayType(StringType()),True)\n  ]\n)\n\n\n\n# using StructType grammar we need a list as input data  thats why below conversion needed\nimport numpy as np\nx=(data_df2.collect()) # collect retrieves all elements in a DataFrame as an Array\ndata_df4 = spark.createDataFrame(data=x,schema=data_schema) # we use Array x as data input -- we cant use another dataframe as input\ndata_df4.printSchema()\n#display(data_df4)\n\nprint(x)\nprint(data_df4)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7184aa79-bec9-4763-8274-ce27e59c77ab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- Title: string (nullable = true)\n |-- Desc: array (nullable = true)\n |    |-- element: string (containsNull = true)\n\n[Row(title='Tacos', directions=['Brown beef', 'Add taco seasoning and water, mix', 'Bring to boil', 'Lower heat to simmer 5-10 minutes until desired consistency', 'Put meat in tacos'])]\nDataFrame[Title: string, Desc: array<string>]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- Title: string (nullable = true)\n |-- Desc: array (nullable = true)\n |    |-- element: string (containsNull = true)\n\n[Row(title='Tacos', directions=['Brown beef', 'Add taco seasoning and water, mix', 'Bring to boil', 'Lower heat to simmer 5-10 minutes until desired consistency', 'Put meat in tacos'])]\nDataFrame[Title: string, Desc: array<string>]\n"]}}],"execution_count":0},{"cell_type":"code","source":["\na1= data_df3.select(col(\"Title\")).toPandas()['Title'].tolist() # instead of using collect to convert , using toPandas and then using tolist to convert from dataframe to list\n\nprint(type(a1))\n\n# using collect func. bcz of retrieving all data , it can cause out of memory error in the case of big dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66154408-318c-46ca-965c-61cbf80a2fea"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<class 'list'>\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["<class 'list'>\n"]}}],"execution_count":0},{"cell_type":"code","source":["display(data_df3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6637793-1591-45e5-b54a-9051b563f047"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Tacos","Brown beef"],["Tacos","Add taco seasoning and water, mix"],["Tacos","Bring to boil"],["Tacos","Lower heat to simmer 5-10 minutes until desired consistency"],["Tacos","Put meat in tacos"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"title","type":"\"string\"","metadata":"{}"},{"name":"col","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>title</th><th>col</th></tr></thead><tbody><tr><td>Tacos</td><td>Brown beef</td></tr><tr><td>Tacos</td><td>Add taco seasoning and water, mix</td></tr><tr><td>Tacos</td><td>Bring to boil</td></tr><tr><td>Tacos</td><td>Lower heat to simmer 5-10 minutes until desired consistency</td></tr><tr><td>Tacos</td><td>Put meat in tacos</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, ArrayType\n\ndata_schema = StructType(\n  [\n    StructField(\"Title\",StringType(),True),\n    StructField(\"Desc\",StringType(),True)\n  ]\n)\n\n\ny=data_df3.select(col(\"Title\"),col('col')).toPandas().values.tolist() # instead of collect we use toPandas and values to covert dataframe into a list\ndata_df4 = spStringTypeark.createDataFrame(data=y,schema=data_schema) # we use Array x as data input -- we cant use another dataframe as input\ndata_df4.printSchema()\n#display(data_df4)\n\nprint(x)\ndisplay(data_df4)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8bee3f1d-6c78-47e5-81fd-d13d4dc501f7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- Title: string (nullable = true)\n |-- Desc: string (nullable = true)\n\n[Row(title='Tacos', directions=['Brown beef', 'Add taco seasoning and water, mix', 'Bring to boil', 'Lower heat to simmer 5-10 minutes until desired consistency', 'Put meat in tacos'])]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- Title: string (nullable = true)\n |-- Desc: string (nullable = true)\n\n[Row(title='Tacos', directions=['Brown beef', 'Add taco seasoning and water, mix', 'Bring to boil', 'Lower heat to simmer 5-10 minutes until desired consistency', 'Put meat in tacos'])]\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Tacos","Brown beef"],["Tacos","Add taco seasoning and water, mix"],["Tacos","Bring to boil"],["Tacos","Lower heat to simmer 5-10 minutes until desired consistency"],["Tacos","Put meat in tacos"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Title","type":"\"string\"","metadata":"{}"},{"name":"Desc","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Title</th><th>Desc</th></tr></thead><tbody><tr><td>Tacos</td><td>Brown beef</td></tr><tr><td>Tacos</td><td>Add taco seasoning and water, mix</td></tr><tr><td>Tacos</td><td>Bring to boil</td></tr><tr><td>Tacos</td><td>Lower heat to simmer 5-10 minutes until desired consistency</td></tr><tr><td>Tacos</td><td>Put meat in tacos</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#using MapType  as input\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructField, StructType, StringType, MapType\n\nschema = StructType([\n    StructField('name', StringType(), True),\n    StructField('properties', MapType(StringType(),StringType()),True)\n])\n\nspark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\ndataDictionary = [\n        ('James',{'hair':'black','eye':'brown'}),\n        ('Michael',{'hair':'brown','eye':None}),\n        ('Robert',{'hair':'red','eye':'black'}),\n        ('Washington',{'hair':'grey','eye':'grey'}),\n        ('Jefferson',{'hair':'brown','eye':''})\n        ]\ndf = spark.createDataFrame(data=dataDictionary, schema = schema)\ndf.printSchema()\ndf.show(truncate=False)\n\n\ndisplay( df.select(col('name') ,col('properties').eye.alias(\"eye\") , col('properties').hair.alias(\"hair\"))  )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2f48ca8-e2f2-45d4-9b93-ca18e403d29d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: string (nullable = true)\n |-- properties: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+----------+-----------------------------+\n|name      |properties                   |\n+----------+-----------------------------+\n|James     |{eye -> brown, hair -> black}|\n|Michael   |{eye -> null, hair -> brown} |\n|Robert    |{eye -> black, hair -> red}  |\n|Washington|{eye -> grey, hair -> grey}  |\n|Jefferson |{eye -> , hair -> brown}     |\n+----------+-----------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: string (nullable = true)\n |-- properties: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+----------+-----------------------------+\n|name      |properties                   |\n+----------+-----------------------------+\n|James     |{eye -> brown, hair -> black}|\n|Michael   |{eye -> null, hair -> brown} |\n|Robert    |{eye -> black, hair -> red}  |\n|Washington|{eye -> grey, hair -> grey}  |\n|Jefferson |{eye -> , hair -> brown}     |\n+----------+-----------------------------+\n\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["James","brown","black"],["Michael",null,"brown"],["Robert","black","red"],["Washington","grey","grey"],["Jefferson","","brown"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"eye","type":"\"string\"","metadata":"{}"},{"name":"hair","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>eye</th><th>hair</th></tr></thead><tbody><tr><td>James</td><td>brown</td><td>black</td></tr><tr><td>Michael</td><td>null</td><td>brown</td></tr><tr><td>Robert</td><td>black</td><td>red</td></tr><tr><td>Washington</td><td>grey</td><td>grey</td></tr><tr><td>Jefferson</td><td></td><td>brown</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#for loop implementation\nprint(type(df))\ndf2=df.select(col('name') ,col('properties').eye.alias(\"eye\") , col('properties').hair.alias(\"hair\"))\nprint(type(df2))\ndf3=df2.toPandas()\nprint(type(df3))\n\nfor index, row in df3.iterrows(): # itterrow only works with pandas.dataframe\n    print(\"\\n\")\n    print(index)\n    print(row['name'], row['hair'])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96e1e7d0-6262-44b6-8b93-c1a00c88ea7e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<class 'pyspark.sql.dataframe.DataFrame'>\n<class 'pyspark.sql.dataframe.DataFrame'>\n<class 'pandas.core.frame.DataFrame'>\n\n\n0\nJames black\n\n\n1\nMichael brown\n\n\n2\nRobert red\n\n\n3\nWashington grey\n\n\n4\nJefferson brown\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["<class 'pyspark.sql.dataframe.DataFrame'>\n<class 'pyspark.sql.dataframe.DataFrame'>\n<class 'pandas.core.frame.DataFrame'>\n\n\n0\nJames black\n\n\n1\nMichael brown\n\n\n2\nRobert red\n\n\n3\nWashington grey\n\n\n4\nJefferson brown\n"]}}],"execution_count":0},{"cell_type":"code","source":["x=(df2.collect())  # collect function can work with <class 'pyspark.sql.dataframe.DataFrame'>\n\n#y=(df3.collect())  # if type is <class 'pandas.core.frame.DataFrame'> we cant use collect function\n\ndisplay(df2.sample(0.20) ) # to get 20% sample records"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e950453a-9774-4476-9607-b96cca799fd5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"eye","type":"\"string\"","metadata":"{}"},{"name":"hair","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>eye</th><th>hair</th></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# working on Parquet File \n\n#Apache Parquet file is a columnar storage format available to any project in the Hadoop ecosystem\n#While querying columnar storage, it skips the nonrelevant data very quickly, making faster query execution. \n#As a result aggregation queries consume less time compared to row-oriented databases.\n\n\n\ndata =[(\"James \",\"\",\"Smith\",\"36636\",\"M\",3000),\n              (\"Michael \",\"Rose\",\"\",\"40288\",\"M\",4000),\n              (\"Robert \",\"\",\"Williams\",\"42114\",\"M\",4000),\n              (\"Maria \",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n              (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)]\ncolumns=[\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\ndfp=spark.createDataFrame(data,columns)\n\n# write into parq. file\ndfp.write.mode('overwrite').parquet(\"/tmp/output/people.parquet\")\n\n# read from parq.\nparDF=spark.read.parquet(\"/tmp/output/people.parquet\")\n\n\ndisplay(parDF)\n\n#execute as sql\n\nparDF.createOrReplaceTempView(\"ParquetTable\")\nparkSQL = spark.sql(\"select * from ParquetTable where salary >= 4000 \")\n\n#CREATE TABLE USING PARQ. FILE\nspark.sql(\"CREATE or REPLACE TEMPORARY VIEW PERSON USING parquet OPTIONS (path \\\"/tmp/output/people.parquet\\\")\")\nspark.sql(\"SELECT * FROM PERSON\").show()\n\n\n#CREATE PARTITIONED PARQ. file\ndfp.write.partitionBy(\"gender\",\"salary\").mode(\"overwrite\").parquet(\"/tmp/output/people2.parquet\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05b11d81-9765-4a24-b640-36dc6f2e94b1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Robert ","","Williams","42114","M",4000],["Maria ","Anne","Jones","39192","F",4000],["Michael ","Rose","","40288","M",4000],["James ","","Smith","36636","M",3000],["Jen","Mary","Brown","","F",-1]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"firstname","type":"\"string\"","metadata":"{}"},{"name":"middlename","type":"\"string\"","metadata":"{}"},{"name":"lastname","type":"\"string\"","metadata":"{}"},{"name":"dob","type":"\"string\"","metadata":"{}"},{"name":"gender","type":"\"string\"","metadata":"{}"},{"name":"salary","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>firstname</th><th>middlename</th><th>lastname</th><th>dob</th><th>gender</th><th>salary</th></tr></thead><tbody><tr><td>Robert </td><td></td><td>Williams</td><td>42114</td><td>M</td><td>4000</td></tr><tr><td>Maria </td><td>Anne</td><td>Jones</td><td>39192</td><td>F</td><td>4000</td></tr><tr><td>Michael </td><td>Rose</td><td></td><td>40288</td><td>M</td><td>4000</td></tr><tr><td>James </td><td></td><td>Smith</td><td>36636</td><td>M</td><td>3000</td></tr><tr><td>Jen</td><td>Mary</td><td>Brown</td><td></td><td>F</td><td>-1</td></tr></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------+----------+--------+-----+------+------+\n|firstname|middlename|lastname|  dob|gender|salary|\n+---------+----------+--------+-----+------+------+\n|  Robert |          |Williams|42114|     M|  4000|\n|   Maria |      Anne|   Jones|39192|     F|  4000|\n| Michael |      Rose|        |40288|     M|  4000|\n|   James |          |   Smith|36636|     M|  3000|\n|      Jen|      Mary|   Brown|     |     F|    -1|\n+---------+----------+--------+-----+------+------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------+----------+--------+-----+------+------+\n|firstname|middlename|lastname|  dob|gender|salary|\n+---------+----------+--------+-----+------+------+\n|  Robert |          |Williams|42114|     M|  4000|\n|   Maria |      Anne|   Jones|39192|     F|  4000|\n| Michael |      Rose|        |40288|     M|  4000|\n|   James |          |   Smith|36636|     M|  3000|\n|      Jen|      Mary|   Brown|     |     F|    -1|\n+---------+----------+--------+-----+------+------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#to_json() function is used to convert DataFrame columns MapType or Struct type to JSON string,,\n\n\n#display(df)\n\nprint( df.printSchema()  )\n\nfrom pyspark.sql.functions import to_json,col\n\ndf.withColumn(\"properties\",to_json(col(\"properties\"))).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"95237919-b273-4239-94a2-f4a83a13476a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- name: string (nullable = true)\n |-- properties: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\nNone\n+----------+------------------------------+\n|name      |properties                    |\n+----------+------------------------------+\n|James     |{\"eye\":\"brown\",\"hair\":\"black\"}|\n|Michael   |{\"eye\":null,\"hair\":\"brown\"}   |\n|Robert    |{\"eye\":\"black\",\"hair\":\"red\"}  |\n|Washington|{\"eye\":\"grey\",\"hair\":\"grey\"}  |\n|Jefferson |{\"eye\":\"\",\"hair\":\"brown\"}     |\n+----------+------------------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- name: string (nullable = true)\n |-- properties: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\nNone\n+----------+------------------------------+\n|name      |properties                    |\n+----------+------------------------------+\n|James     |{\"eye\":\"brown\",\"hair\":\"black\"}|\n|Michael   |{\"eye\":null,\"hair\":\"brown\"}   |\n|Robert    |{\"eye\":\"black\",\"hair\":\"red\"}  |\n|Washington|{\"eye\":\"grey\",\"hair\":\"grey\"}  |\n|Jefferson |{\"eye\":\"\",\"hair\":\"brown\"}     |\n+----------+------------------------------+\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["#overlay() Function\n#Replace column value with a string value from another column.\n\nfrom pyspark.sql.functions import overlay\ndf = spark.createDataFrame([(\"ABCDE_XYZ\", \"FGH\")], (\"col1\", \"col2\"))\ndf.select(overlay(\"col1\", \"col2\",0).alias(\"overlayed\")).show()\ndf.select(overlay(\"col1\", \"col2\",1).alias(\"overlayed\")).show()\ndf.select(overlay(\"col1\", \"col2\",6).alias(\"overlayed\")).show()\n\n\nx=df.select(overlay(\"col1\", \"col2\",6).alias(\"overlayed\")).toPandas().values.tolist() \n\nprint(type(x))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82c1de38-c5f7-4421-956d-25a95371da18"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----------+\n| overlayed|\n+----------+\n|FGHCDE_XYZ|\n+----------+\n\n+---------+\n|overlayed|\n+---------+\n|FGHDE_XYZ|\n+---------+\n\n+---------+\n|overlayed|\n+---------+\n|ABCDEFGHZ|\n+---------+\n\n<class 'list'>\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+\n| overlayed|\n+----------+\n|FGHCDE_XYZ|\n+----------+\n\n+---------+\n|overlayed|\n+---------+\n|FGHDE_XYZ|\n+---------+\n\n+---------+\n|overlayed|\n+---------+\n|ABCDEFGHZ|\n+---------+\n\n<class 'list'>\n"]}}],"execution_count":0},{"cell_type":"code","source":["# read json example 2\nfrom pyspark.sql.types import *\n\n# Read multiline json file 1\ndata_df = spark.read.option(\"multiline\",\"true\").json(\"/FileStore/tables/JSON/Ex1.json\")\ndisplay(data_df) \n\nprint(data_df.printSchema() )\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e137e80-efee-4ed3-85ae-acd2ad18c210"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[[[["1001","Regular"],["1002","Chocolate"],["1003","Blueberry"],["1004","Devil's Food"]]],"0001","Cake",0.55,[["5001","None"],["5002","Glazed"],["5005","Sugar"],["5007","Powdered Sugar"],["5006","Chocolate with Sprinkles"],["5003","Chocolate"],["5004","Maple"]],"donut"],[[[["1001","Regular"]]],"0002","Raised",0.55,[["5001","None"],["5002","Glazed"],["5005","Sugar"],["5003","Chocolate"],["5004","Maple"]],"donut"],[[[["1001","Regular"],["1002","Chocolate"]]],"0003","Old Fashioned",0.55,[["5001","None"],["5002","Glazed"],["5003","Chocolate"],["5004","Maple"]],"donut"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"batters","type":"{\"type\":\"struct\",\"fields\":[{\"name\":\"batter\",\"type\":{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"type\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true},\"nullable\":true,\"metadata\":{}}]}","metadata":"{}"},{"name":"id","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"ppu","type":"\"double\"","metadata":"{}"},{"name":"topping","type":"{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"id\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"type\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true}","metadata":"{}"},{"name":"type","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>batters</th><th>id</th><th>name</th><th>ppu</th><th>topping</th><th>type</th></tr></thead><tbody><tr><td>List(List(List(1001, Regular), List(1002, Chocolate), List(1003, Blueberry), List(1004, Devil's Food)))</td><td>0001</td><td>Cake</td><td>0.55</td><td>List(List(5001, None), List(5002, Glazed), List(5005, Sugar), List(5007, Powdered Sugar), List(5006, Chocolate with Sprinkles), List(5003, Chocolate), List(5004, Maple))</td><td>donut</td></tr><tr><td>List(List(List(1001, Regular)))</td><td>0002</td><td>Raised</td><td>0.55</td><td>List(List(5001, None), List(5002, Glazed), List(5005, Sugar), List(5003, Chocolate), List(5004, Maple))</td><td>donut</td></tr><tr><td>List(List(List(1001, Regular), List(1002, Chocolate)))</td><td>0003</td><td>Old Fashioned</td><td>0.55</td><td>List(List(5001, None), List(5002, Glazed), List(5003, Chocolate), List(5004, Maple))</td><td>donut</td></tr></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- batters: struct (nullable = true)\n |    |-- batter: array (nullable = true)\n |    |    |-- element: struct (containsNull = true)\n |    |    |    |-- id: string (nullable = true)\n |    |    |    |-- type: string (nullable = true)\n |-- id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- ppu: double (nullable = true)\n |-- topping: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- id: string (nullable = true)\n |    |    |-- type: string (nullable = true)\n |-- type: string (nullable = true)\n\nNone\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- batters: struct (nullable = true)\n |    |-- batter: array (nullable = true)\n |    |    |-- element: struct (containsNull = true)\n |    |    |    |-- id: string (nullable = true)\n |    |    |    |-- type: string (nullable = true)\n |-- id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- ppu: double (nullable = true)\n |-- topping: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- id: string (nullable = true)\n |    |    |-- type: string (nullable = true)\n |-- type: string (nullable = true)\n\nNone\n"]}}],"execution_count":0},{"cell_type":"code","source":["#using MapType  as input\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructField, StructType, StringType, MapType\n\nschema = StructType([\n  StructField('id',StringType()),\n  StructField('batters', StructType([\n    \n        StructField(\n        'batter', ArrayType(\n            StructType([\n                StructField('id', StringType(), True),\n                StructField('type',StringType() , True) \n               \n                \n            ])\n        )\n    )\n    \n    \n  ])  )\n])\n\ndfx=data_df[[\"id\",\"batters\"]].toPandas().values.tolist()\n\n\ndf = spark.createDataFrame(data=dfx, schema = schema)\ndisplay(   df.select(col(\"id\"),col(\"batters\").batter.id,col(\"batters\").batter.type    )   )\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3151d86b-a85f-4104-9f3b-df82ec40db92"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["0001",["1001","1002","1003","1004"],["Regular","Chocolate","Blueberry","Devil's Food"]],["0002",["1001"],["Regular"]],["0003",["1001","1002"],["Regular","Chocolate"]]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"id","type":"\"string\"","metadata":"{}"},{"name":"batters.batter.id","type":"{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}","metadata":"{}"},{"name":"batters.batter.type","type":"{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>batters.batter.id</th><th>batters.batter.type</th></tr></thead><tbody><tr><td>0001</td><td>List(1001, 1002, 1003, 1004)</td><td>List(Regular, Chocolate, Blueberry, Devil's Food)</td></tr><tr><td>0002</td><td>List(1001)</td><td>List(Regular)</td></tr><tr><td>0003</td><td>List(1001, 1002)</td><td>List(Regular, Chocolate)</td></tr></tbody></table></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"PySpark Data Op","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2033568028168007}},"nbformat":4,"nbformat_minor":0}
